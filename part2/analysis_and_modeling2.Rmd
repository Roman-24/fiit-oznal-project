---
title: "OZNAL Zadanie 2"
author: "Roman Bitarovsky a Roman Osadsky"
date: "09.04.2024"
output: html_document
---

# Predstavenie datasetu
Náš dataset obsahuje informácie o ovzduší a meracích staniciach ktoré dané merania vykonávali.
Je zložený z dvoch súborov a to:
- measurements.csv
- stations.csv
## Skratky:
- PM2.5 - Particulate Matter (µg/m3) <br>
- PM10 - Particulate Matter (µg/m3) <br>
- NOx - Nitrogen Oxides (µg/m3) <br>
- NO2 - Nitrogen Dioxide (µg/m3) <br>
- SO2 - Sulfur Dioxide  (µg/m3) <br>
- CO - Carbon Monoxide emissions  (µg/m3) <br>
- CO2 - Carbon Dioxide  (µg/m3) <br>
- PAHs - Polycyclic Aromatic Hydrocarbons  (µg/m3) <br>
- NH3 - Ammonia trace  (µg/m3) <br>
- Pb - Lead  (µg/m3) <br>
- TEMP - Temperature (degree Celsius) <br>
- DEWP - Dew point temperature (degree Celsius) <br>
- PRES - Pressure (hPa, <100, 1050>) <br>
- RAIN - Rain (mm) <br>
- WSPM - Wind Speed (m/s) <br>
- WD - Wind Direction <br>
- VOC - Volatile Organic Compounds <br>
- CFCs - Chlorofluorocarbons <br>
- C2H3NO5 - Peroxyacetyl nitrate <br>
- H2CO - Plywood emit formaldehyde <br>
- GSTM1 - Glutathione-S transferase M1 <br>
- 1-OHP - 1-hydroxypyrene <br>
- 2-OHF - 2-hydroxyfluorene <br>
- 2-OHNa - 2-hydroxynaphthalene <br>
- N2 - Nitrogen <br>
- O2 - Oxygen <br>
- O3 - Ozone <br>
- Ar - Argon <br>
- Ne - Neon <br>
- CH4 - Methane <br>
- He - Helium <br>
- Kr - Krypton <br>
- I2 - Iodine <br>
- H2 - Hydrogen <br>
- Xe - Xenon <br>

# Initializácia a načítanie dát
```{r}
getwd()
#setwd('/Users/roman.osadsky/Desktop/ROMAN/FIIT/OZNAL_PROJECT/oznal_project1')
setwd('/Users/roman/Desktop/development/oznal_project1/')
#setwd(getwd())
```
Importovanie knižníc
```{r}
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyverse)
library(caret)
library(tidyr)
library(e1071)
library(corrplot)
library(MASS)
library(reshape2)
library(gridExtra)
library(pROC)
library(glmnet)
library(PRROC)

```
Načítanie dát
```{r}
labor_measurements <- read.csv('/Users/roman/Desktop/development/oznal_project1/data/measurements.csv', sep = '\t')
labor_stations <- read.csv('/Users/roman/Desktop/development/oznal_project1/data/stations.csv', sep = '\t')
```


# Základné preskúmanie dát
Zobrazenie prvých riadkov datasetov, ich rozmerov a typov atribútov

## Merenia
```{r}
head(labor_measurements)
```
Počet riadkov: labor_measurements
```{r}
nrow(labor_measurements)
```
Počet stĺpcov: labor_measurements
```{r}
ncol(labor_measurements)
```
### Atribúty labor_measurements
```{r}
str(labor_measurements)
```

## Stanice
```{r}
head(labor_stations)
```
Počet riadkov: labor_stations
```{r}
nrow(labor_stations)
```
Počet stĺpcov: labor_stations
```{r}
ncol(labor_stations)
```
### Atribúty labor_stations
```{r}
str(labor_stations)
```


# Čistenie dát
Ked sa pozrieme na labor_stations tam už to tak nieje preto si skontrolujeme formáty

## Zjednotenie atribútov
```{r}
# Kontrola jedinečných hodnôt a ich počtu
qos_count <- table(labor_stations$QoS)
#qos_count
# Nahradenie špecifických hodnôt
labor_stations$QoS[labor_stations$QoS == "acceptable"] <- "accep"
labor_stations$QoS[labor_stations$QoS == "maitennce"] <- "maintenance"
# Opätovná kontrola jedinečných hodnôt a ich počtov po nahradení
qos_count <- table(labor_stations$QoS)
#qos_count
```
helper
```{r}
parse_dates <- function(date_string) {
  formats <- c("%Y/%m/%d", "%d %b %Y", "%Y-%m-%d", "%m/%d/%Y, %H:%M:%S", "%d/%m/%Y, %H:%M:%S")

  for (format in formats) {
    parsed_date <- as.POSIXct(date_string, format = format, tz = "")
    if (!is.na(parsed_date)) {
      # urob datum na format "28 Aug 2016"
      return(format(parsed_date, "%d %b %Y"))
    }
  }

  return(NA)
}
```
```{r}
# Kontrola jedinečných hodnôt a ich počtu
revision_count <- table(labor_stations$revision)
#revision_count
# Nahradenie špecifických hodnôt
labor_stations$revision <- sapply(labor_stations$revision, parse_dates)
cat('Identifikované rozdielne formáty dátumu sme zjednotili na formát dd mmm yyyy')
# Opätovná kontrola jedinečných hodnôt a ich počtov po nahradení
revision_count <- table(labor_stations$revision)
#revision_count
```

## Nahradenie chýbajúcich hodnôt

```{r}
# Nahradenie prázdnych reťazcov reťazcami NA
labor_measurements[labor_measurements == ""] <- NA
labor_stations[labor_stations == ""] <- NA
```
Náhľad nato koľko dát chýba
```{r}
missing_data_percentage <- sum(is.na(labor_measurements)) / nrow(labor_measurements) * 100
cat(sprintf("Chýbajúce dáta v labor_measurements tvoria %.5f%% dát", missing_data_percentage))
cat("\n")
missing_data_percentage_stations <- sum(is.na(labor_stations)) / nrow(labor_stations) * 100
cat(sprintf("Chýbajúce dáta v labor_stations tvoria %.5f%% dát", missing_data_percentage_stations))
cat("\n")
```
Spočítanie a vypísanie riadkov s hodnotami NA pre labor_measurements
```{r}
na_count_measurements <- sum(!complete.cases(labor_measurements))
cat('NaN hodnoty pre labor_measurements:', na_count_measurements, '\n')
```
Spočítanie a vypísanie riadkov s hodnotami NA pre labor_stations
```{r}
na_count_stations <- sum(!complete.cases(labor_stations))
cat('NaN hodnoty pre labor_stations:', na_count_stations, '\n')
```
Prázdne hodnoty sme sa rozhodli dropnúť
```{r}
labor_measurements <- na.omit(labor_measurements)
labor_stations <- na.omit(labor_stations)
```

## Kontrola duplicitných záznamov
```{r}
if (any(duplicated(labor_measurements))) {
  duplicates_count <- sum(duplicated(labor_measurements))
  cat('labor_measurements pocet duplikatov', duplicates_count, '\n')
} else {
  cat('labor_measurements no duplicates\n')
}
if (any(duplicated(labor_stations))) {
  duplicates_count_stations <- sum(duplicated(labor_stations))
  cat('labor_stations pocet duplikatov', duplicates_count_stations, '\n')
} else {
  cat('labor_stations no duplicates\n')
}
```
Dropnutie duplicitných záznamov
```{r}
labor_measurements <- unique(labor_measurements)
labor_stations <- unique(labor_stations)
```

# Mergnutie súborov do jedného df
```{r}
# Odstránenie nepotrebných stĺpcov
labor_stations <- labor_stations[, -4]
#head(labor_stations)
# Merge
df <- merge(labor_measurements, labor_stations, by = c("latitude", "longitude"), all = FALSE)
# Odstránenie stĺpcov 'latitude' a 'longitude' lebo ich už viac nepotrebujeme
df <- df[, !names(df) %in% c('latitude', 'longitude')]
# reorganizacia stlpcov
df <- df[, c('location', 'warning', 'QoS', 'revision', 'TEMP', 'PRES', 'PM2.5', 'NOx', 'PM10', 'C2H3NO5', 'CH4', 'Pb', 'NH3', 'SO2', 'O3', 'CO', 'PAHs', 'H2CO', 'CFCs')]
head(df)
```

# Outliers
```{r}
df_out <- df[, c('TEMP', 'PRES', 'PM2.5', 'NOx', 'PM10', 'C2H3NO5', 'CH4', 'Pb', 'NH3', 'SO2', 'O3', 'CO', 'PAHs', 'H2CO', 'CFCs')]
head(df_out)
outliers_list <- lapply(df_out, function(column) {
  IQR_value <- IQR(column, na.rm = TRUE)
  upper_bound <- quantile(column, 0.75, na.rm = TRUE) + 1.5 * IQR_value
  lower_bound <- quantile(column, 0.25, na.rm = TRUE) - 1.5 * IQR_value
  lower_outliers <- which(column < lower_bound)
  upper_outliers <- which(column > upper_bound)
  return(list(lower_outliers = lower_outliers, upper_outliers = upper_outliers))
})


plot(df_out[[1]], main=paste("Outliers in", names(df_out)[1]), col="blue", pch=19)
if(length(outliers_list[[1]]$lower_outliers) > 0) {
  points(outliers_list[[1]]$lower_outliers, df_out[outliers_list[[1]]$lower_outliers, 1], col="red", pch=19)
}
if(length(outliers_list[[1]]$upper_outliers) > 0) {
  points(outliers_list[[1]]$upper_outliers, df_out[outliers_list[[1]]$upper_outliers, 1], col="red", pch=19)
}

```

# Pokročilé skúmanie dát

## Lineárna regressia

```{r}
numeric_df <- df[sapply(df, is.numeric)]
ggpairs(numeric_df,
        lower = list(continuous = "smooth"),
        diag = list(continuous = "barDiag"))
```

### Rozdelíme dáta na trénovacie a testovacie a vytvoríme Model

```{r}
set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(df), replace = TRUE, prob = c(0.5, 0.3))
train_data <- df[sample,]
test_data <- df[!sample,]

# PM2.5 – the most harmful pollution
# PM10 - Particulate Matter (µg/m3)
# SO2 - Sulfur Dioxide  (µg/m3)
# CO - Carbon Monoxide emissions  (µg/m3)
PM25Model <- lm(PM2.5 ~ PM10  + SO2 + CO, data = train_data)
summary(PM25Model)
```
#### Vyhodnotenie na základe summary

- Odhadovaná štandardná chyba reziduál je 1.588, čo naznačuje rozptyl reziduálnych hodnôt okolo regresnej čiary.
- F-statisticsje 2405 na 3 a 15103 DF, s p-hodnotou menšou ako 2.2e-16, čo naznačuje, že model ako celok je štatisticky významný. (Čím vačší F-statistics tým lepšie)
- Std. Error je na nízkých hodnotách, tak môžeme povedať že chybovosť modelu má menšiu pravdepodobnost
- r-squared by malo isť viac k 1 aby to bolo presnejšie
- p-value je < 0.05  model je štatisticky signifikantný
- t-value je celkom na vysokých hodnotách čo môže naznačovať koeficient regresie nieje štatisticky významný


### Vy-plotujeme si model

```{r}

par(mar = c(1, 1, 1, 1))
plot(PM25Model)
```

### Vyhodnotenie plotov

Residuals vs Fitted
- Červená čiara by mala horizontálna najviac ako je možná
- Ak je čiara nakrivená može to znamenať nelineárny vzťah
- Detekuje odlahlé body

Normal QQ
- Kontrolujeme či residuals majú normálovu distribúciu
- Ak sú rezíduá normálne distribuované, body na grafe by mali vytvoriť približne priamu čiaru
- Ak sú body na Q-Q grafe zakrivené alebo majú iné neštandardné vzory, môže to naznačovať, že rezíduá majú neobvyklé rozdelenie
- V našom prípade to vyzerá že residualy majú normálovú distribúciu

Scale-Location (Spread location)
- Čiara je takmer horizontálna takže mohli by sme povedať že residuals sú rovnomerne rozložené

Residuals vs Leverage:
- zobrazuje ovplivnujúce časti
- niečo podobné ako outliery
- ak by sme videli v rohoch čiary tak je možné že to nieje v poriadku


## Predikovanie na základe testovacích dáta + manuálne overenie

```{r}


predicted_values <- predict(PM25Model, newdata = test_data)

# PM25 = 12.88 - 0.11 * PM10 - 0.23 * SO2 + 0.10 * CO
cat("Expected: 5.72081 , Predicted: ",predict(PM25Model,data.frame(PM10=5.85838,  SO2=11.00024, CO=7.00959)))
```


```{r}

mean_absolute_error <- mean(abs(predicted_values - test_data$PM2.5))
mean_squared_error <- mean((predicted_values - test_data$PM2.5)^2)
root_mean_squared_error <- sqrt(mean_squared_error)

data.frame(Metric = c("Mean Absolute Error", "Mean Squared Error", "Root Mean Squared Error"), Value = c(mean_absolute_error,mean_squared_error,root_mean_squared_error))

```

### Vyhodnotenie na základe metrík
MAE - meria absolutnu chybu medzi predikovanými hodnotami a skutočnímy

MSE - meria priemernu velkost chyb p redikciach modelu, a tak kvantifikuje rozdiel medzi skutočnými a predikovanými hodnotami

RMSE -> poskytuje prehlad o tom ako dobre model predikuje alebo ako blízko sú predikcie k skutočním hodnotám


### Vizualizácia predikovaných dát

```{r}
plot(x=predicted_values, y=test_data$PM2.5,
     xlab='Predicted Values',
     ylab='Actual Values',
     main='Predicted vs. Actual Values')

head(data.frame(actual=test_data$PM2.5, predicted=predicted_values))

```

## Klasifikácia

Warning je kategorický atribút, preto ho musíme pretypovať na faktor
```{r}
df$warning <- as.factor(df$warning)
```
### Rozdelenie train a test
```{r}
set.seed(123)
#cat('nrow', nrow(df))
#cat('ncol', ncol(df))
index <- sample(seq_len(nrow(df)), round(0.7 * nrow(df)))
trainData <- df[index,]
testData <- df[-index,]
```

### Natrenovanie modelu
```{r}
# binomial distribúcii, ktorá je vhodná pre binárnu logistickú regresiu.
logisticModel <- glm(warning ~ PM2.5 + PM10 + NH3 + C2H3NO5, data = trainData, family = binomial())
```
- Std. Error: Štandardné chyby odhadov koeficientov. Menšie hodnoty ukazujú väčšiu presnosť odhadov koeficientov.
- P-hodnoty pre testy z. Nízke p-hodnoty (v tomto prípade menšie ako 2e-16) naznačujú, že príslušné koeficienty sú štatisticky významné.
- V tomto prípade všetky prediktívne premenné majú významný vplyv na premennú
```{r}
summary(logisticModel)
```
#### Predikcia na teste
```{r}
# výpočet predpovedí logistickej regresie na základe predtým natrénovaného modelu
probabilities <- predict(logisticModel, newdata = testData, type = "response")

# Na základe vrátených pravdepodobností priraďujeme triedy
# Ak je pravdepodobnosť väčšia ako 0.5, priradí sa hodnota reprezentujúca TRUE warning
# Ak je menšia alebo rovná 0.5, priradí sa FALSE warning
glmPredictions <- ifelse(probabilities > 0.5, levels(testData$warning)[2], levels(testData$warning)[1])

# konvertuje predpovedané hodnoty na faktorovú premennú s úrovňami definovanými v originálnej premennej
glmPredictions <- factor(glmPredictions, levels = levels(testData$warning))
```
#### Evaluacia modelu
```{r}
confMatrix <- table(Predicted = glmPredictions, Actual = testData$warning)
print(confMatrix)
```

confusionMatrix je tabuľka, ktorá ukazuje počty správnych a nesprávnych predikcií modelu v porovnaní s aktuálnymi hodnotami.
V tomto prípade sú predictions predpovedané hodnoty z modelu, a testData$warning sú skutočné hodnoty cieľovej premennej.
Objekt confMat potom obsahuje túto metriku spolu s ďalšími štatistikami výkonu modelu.
```{r}
confMat <- confusionMatrix(glmPredictions, testData$warning)
confMatMatrix <- as.matrix(confMat$table)
```

Melt mení confMatMatrix do dlhého formátu.
Dlhý formát je užitočný pre vizualizáciu, pretože každý riadok reprezentuje jednu hodnotu s príslušnými identifikátormi.
Výsledný objekt confMatMelted má tri stĺpce:
- jeden pre skutočné hodnoty
- jeden pre predpovedané hodnoty
- a jeden pre počet pozorovaní pre každú kombináciu skutočných a predpovedaných hodnôt
```{r}
confMatMelted <- melt(confMatMatrix)
# Actual - predstavuje skutočné hodnoty
# Predicted - predikované hodnoty
# Value - počet prípadov pre každú kombináciu skutočnej a predpovedanej hodnoty
colnames(confMatMelted) <- c('Actual', 'Predicted', 'Value')
```
### Konštatovanie výsledkov
```{r}
# Vytvorenie ROC objektu
roc_obj <- roc(testData$warning, probabilities)

# Výpis ROC krivky
plot(roc_obj, main="ROC Krivka")

# Hľadanie optimálneho cut-off bodu
# Zvyčajne chceme maximalizovať Youdenov index (J), ktorý je definovaný ako sensitivity + specificity - 1
coords(roc_obj, "best", best.method="youden")


```
Vráti napríklad:
- threshold (cut-off bod) - je hodnota, ktorá slúži ako hranica na rozhodovanie medzi dvoma možnosťami <br>
- specificity -  pravdepodobnosť, že model predpovedá pozitívny výsledok pozorovania, keď je výsledok skutočne pozitívny <br>
- sensitivity - pravdepodobnosť, že model predpovedá negatívny výsledok pozorovania, keď je výsledok skutočne negatívny

```{r}
# Vypočítajme krivku ROC a nájdime optimálny point
roc_obj <- roc(testData$warning, probabilities)
optimal <- coords(roc_obj, "best", best.method="youden")
optimal_threshold <- optimal$threshold

# Kontrola platnosti optimálnych súradníc
if (!is.null(optimal$x) && !is.null(optimal$y)) {
  # Plot ROC curve
  plot(roc_obj, main="ROC Curve with Optimal Threshold")

  # bod pre optimal threshold
  points(optimal$x, optimal$y, pch=19, col="red")

  # pridaj text label pre optimal threshold
  text(optimal$x, optimal$y, labels=paste("Threshold:", round(optimal_threshold, 3)), pos=4)
    segments(optimal$x, optimal$y, optimal$x, 0, col="red", lty=2)
} else {
  cat("Optimal coordinates are not available.\n")
}

```
```{r}
p <- ggplot(confMatMelted, aes(x = Actual, y = Predicted, fill = Value)) +
  geom_tile(color = "white") +  # Tiles for each combination of actual and predicted
  geom_text(aes(label = Value), color = "black", size = 5) +  # prida text pre kazdu dlaždicu
  scale_fill_gradient(low = "white", high = "steelblue") +  # farba gradientu
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +  # prida x-axis text
  xlab('Predicted') +  # X-axis label
  ylab('Actual') +  # Y-axis label
  ggtitle('Confusion Matrix - Logistic Regression')  # title
```
- Ľavá horná dlaždica (604) predstavuje pravé negatíva (TN): prípady, keď model správne predpovedal negatívnu triedu.
- Ľavá spodná dlaždica (1542) predstavuje falošné negatíva (FN): prípady, keď model nesprávne predpovedal negatívnu triedu, hoci v skutočnosti bola pozitívna.
- Pravá horná dlaždica (3699) predstavuje pravé pozitíva (TP): prípady, keď model správne predpovedal pozitívnu triedu.
- Pravá spodná časť (1391) predstavuje falošné pozitívne výsledky (FP): prípady, keď model nesprávne predpovedal pozitívnu triedu, hoci v skutočnosti bola negatívna.
```{r}
print(p)
```

# Pokročilé skúmanie dát 2

## Lineárna regressia

### Lasso regresia

```{r}
## Lasso regresion

head(df)
library(glmnet)

sample2 <- sample(c(TRUE, FALSE), nrow(df), replace = TRUE, prob = c(0.5, 0.3))
train_data <- df[sample2,]
test_data <- df[!sample2,]

# Nastavenie cieľovej hodnoty na PM2.5
y_train_data <- train_data$PM2.5
y_test_data <- test_data$PM2.5

# Nastavenie nezávislých premenných na PM10, SO2 a CO a vytvorenie matice dát
x_train_data <- data.matrix(train_data[, c('PM10', 'SO2', 'CO')])
x_test_data <- data.matrix(test_data[, c('PM10', 'SO2', 'CO')])


x_train_data_SO2_CO <- data.matrix(train_data[, c('SO2', 'CO')])
x_test_data_SO2_CO <- data.matrix(test_data[, c('SO2', 'CO')])


x_train_data_C2H3NO5_NH3_PM10 <- data.matrix(train_data[, c('C2H3NO5', 'NH3', 'PM10')])
x_test_data_C2H3NO5_NH3_PM10<- data.matrix(test_data[, c('C2H3NO5', 'NH3', 'PM10')])

# Vytvorenie modelu
# cv = Cros validation pre nájdenie optimálnej hodnoty pre Lambdu
# gausiann -> dávame vedieť že robíme lineárnu regresiu
cv_model <- cv.glmnet(x_train_data, y_train_data, alpha = 1, family = "gaussian")
cv_model_SO2_CO <- cv.glmnet(x_train_data_SO2_CO, y_train_data, alpha = 1, family = "gaussian")
cv_model_C2H3NO5_NH3_PM10 <- cv.glmnet(x_train_data_C2H3NO5_NH3_PM10, y_train_data, alpha = 1, family = "gaussian")

# Určenie optimálnej hodnoty lambda z krížovej validácie
#hyperparameter lambda (λ) - vyvažuje kompromis medzi odchýlkou a rozptylom vo výsledných koeficientoch.
best_lambda <- cv_model$lambda.min
best_lambda_SO2_CO <- cv_model_SO2_CO$lambda.min
best_lambda_C2H3NO5_NH3_PM10 <- cv_model_C2H3NO5_NH3_PM10$lambda.min


# Vykreslenie grafu krížovej validácie
plot(cv_model)

# Získanie koeficientov najlepšieho modelu
best_model <- glmnet(x_train_data, y_train_data, alpha = 1, lambda = best_lambda)
best_model_SO2_CO <- glmnet(x_train_data_SO2_CO, y_train_data, alpha = 1, lambda = best_lambda_SO2_CO)
best_model_C2H3NO5_NH3_PM10 <- glmnet(x_train_data_C2H3NO5_NH3_PM10, y_train_data, alpha = 1, lambda = best_lambda_C2H3NO5_NH3_PM10)

coef(best_model)

# Predikcia hodnôt pomocou najlepšieho modelu
y_predicted <- predict(best_model, s = best_lambda, newx = x_test_data)
y_predicted_S02_CO <- predict(best_model_SO2_CO, s = best_lambda_SO2_CO, newx = x_test_data_SO2_CO)
y_predicted_C2H3NO5_NH3_PM10 <- predict(best_model_C2H3NO5_NH3_PM10, s = best_lambda_C2H3NO5_NH3_PM10, newx = x_test_data_C2H3NO5_NH3_PM10)


sst <- sum((y_test_data - mean(y_test_data))^2)
sse <- sum((y_predicted - y_test_data)^2)
rsq <- 1 - sse/sst
rsq


sst <- sum((y_test_data - mean(y_test_data))^2)
sse <- sum((y_predicted_S02_CO - y_test_data)^2)
rsq_SO2_CO <- 1 - sse/sst
rsq_SO2_CO

sst <- sum((y_test_data - mean(y_test_data))^2)
sse <- sum((y_predicted_C2H3NO5_NH3_PM10 - y_test_data)^2)
rsq_C2H3NO5_NH3_PM10 <- 1 - sse/sst
rsq_C2H3NO5_NH3_PM10


# Create a data frame with these values
rsq_values <- data.frame(
        Model = c("Model 1", "Model SO2_CO", "Model C2H3NO5_NH3_PM10"),
        RSquared = c(rsq, rsq_SO2_CO, rsq_C2H3NO5_NH3_PM10)
)

# Print the table
print(rsq_values)




##TODO COMBINACIA PREDIKTOROV

```

## Klasifikácia

### LDA

```{r}

# rozdelenie data setu na test a train
# nieje potrebne lebo je urobene hore
set.seed(123)
index <- sample(seq_len(nrow(df)), round(0.7 * nrow(df)))
trainData <- df[index,]
testData <- df[-index,]

# Trénovanie modelu Linear Discriminant Analysis (LDA)
ldaModel <- lda(warning ~ PM2.5 + PM10 + NH3 + C2H3NO5, data = trainData)

# Predpovedanie na testovacom súbore údajov
ldaPredictions <- predict(ldaModel, newdata = testData)$class

# evaluacia modelu
table(Predicted = ldaPredictions, Actual = testData$warning)
```

#### LDA tweak 1
```{r}
# Trénovanie modelu Linear Discriminant Analysis (LDA)
ldaModelTweak1 <- lda(warning ~ NH3 + C2H3NO5, data = trainData)

# Predpovedanie na testovacom súbore údajov
ldaPredictionsTweak1 <- predict(ldaModelTweak1, newdata = testData)$class

# evaluacia modelu
table(Predicted = ldaPredictionsTweak1, Actual = testData$warning)
```

### SVM
SVM sú typom algoritmu učenia pod dohľadom, ktorý sa používa na klasifikačné aj regresné úlohy.
Sú obzvlášť výkonné pre vysokorozmerné údaje.
Cieľom SVM je nájsť najlepšiu oddeľujúcu hyperplochu, ktorá rozdeľuje rôzne triedy v priestore príznakov.
Vektory, ktoré definujú hyperplochu, sa nazývajú podporné vektory.

Kernel je metóda používaná v SVM, ktorá umožňuje učenie vo vysokodimenzionálnych priestoroch príznakov bez explicitnej transformácie údajov do týchto dimenzií.
Je to užitočné najmä vtedy, keď hranica medzi triedami nie je lineárna.
Použitím funkcie jadra môže SVM vykonávať zložité klasifikácie pomocou lineárneho klasifikátora implicitným mapovaním vstupných údajov do vysokodimenzionálnych priestorov príznakov.

#### Radial Basis Function (RBF) Kernel
Kernel RBF je jednou z najbežnejších funkcií používaných v SVM. Označuje sa aj ako Gaussov kernel.
Výhody použitia jadra RBF v SVM
- RBF jadro je veľmi flexibilné a dokáže riešiť prípady, keď je vzťah medzi značkami tried a atribútmi nelineárny.
- Funguje dobre vo vysokodimenzionálnych priestoroch, aj keď je počet dimenzií väčší ako počet vzoriek.
- Je účinný v scenároch, kde dátové body nie sú lineárne oddeliteľné.
#### Others
kernel options available in e1071:
- Linear Kernel: This kernel is the simplest, where the prediction is based on the linear combination of the features. It's used when the data is linearly separable. You can specify it with kernel = "linear".
- Polynomial Kernel: This kernel allows for curved boundaries in the feature space. It's defined by the degree of the polynomial. Higher degrees can fit more complex structures but also risk overfitting. It can be specified using kernel = "polynomial", and you can also set the degree with the degree parameter.
- Radial Basis Function (RBF) Kernel: Also known as the Gaussian kernel, this is a popular choice for many classification problems. It can map the data into an infinite-dimensional space and is effective in handling non-linear relationships. It's used with kernel = "radial".
- Sigmoid Kernel: This kernel functions like the sigmoid function in logistic regression. It can be specified with kernel = "sigmoid". This is similar to a two-layer, perceptron neural network.
```{r}

set.seed(123)
index <- sample(seq_len(nrow(df)), round(0.7 * nrow(df)))
trainData <- df[index,]
testData <- df[-index,]

# trenovanie SVM modelu
svmModel <- svm(warning ~ PM2.5 + PM10 + NH3 + C2H3NO5, data = trainData, kernel = "radial", cost = 1, scale = TRUE)
summary(svmModel)
# generovanie predpovedí
svmPredictions <- predict(svmModel, newdata = testData)
# prevod predpovedí na faktor s úrovňami ako v testovacích údajoch
svmPredictions <- factor(svmPredictions, levels = levels(testData$warning))
# Confusion Matrix pre SVM model
svmConfMatrix <- table(Predicted = svmPredictions, Actual = testData$warning)
print(svmConfMatrix)
# pokročilé vyhodnotie
confusionMatrix(svmPredictions, testData$warning)

```
#### SVM tweak 1
```{r}
# trenovanie SVM modelu
svmModelTweak1 <- svm(warning ~ NH3 + C2H3NO5, data = trainData, kernel = "radial", cost = 1, scale = TRUE)
summary(svmModelTweak1)
# generovanie predpovedí
svmPredictionsTweak1 <- predict(svmModelTweak1, newdata = testData)
# prevod predpovedí na faktor s úrovňami ako v testovacích údajoch
svmPredictionsTweak1 <- factor(svmPredictionsTweak1, levels = levels(testData$warning))
# Confusion Matrix pre SVM model
svmConfMatrixTweak1 <- table(Predicted = svmPredictionsTweak1, Actual = testData$warning)
print(svmConfMatrixTweak1)
# pokročilé vyhodnotie
confusionMatrix(svmPredictionsTweak1, testData$warning)
```
#### SVM tweak 2
```{r}
# trenovanie SVM modelu
svmModelTweak2 <- svm(warning ~ NOx + C2H3NO5 + CH4 + Pb + SO2 + O3 + CO + PAHs + H2CO + CFCs, data = trainData, kernel = "radial", cost = 1, scale = TRUE)
summary(svmModelTweak2)
# generovanie predpovedí
svmPredictionsTweak2 <- predict(svmModelTweak2, newdata = testData)
# prevod predpovedí na faktor s úrovňami ako v testovacích údajoch
svmPredictionsTweak2 <- factor(svmPredictionsTweak2, levels = levels(testData$warning))
# Confusion Matrix pre SVM model
svmConfMatrixTweak2 <- table(Predicted = svmPredictionsTweak2, Actual = testData$warning)
print(svmConfMatrixTweak2)
# pokročilé vyhodnotie
confusionMatrix(svmPredictionsTweak2, testData$warning)
```

## Porovnanie modelov klasifikácie

### Basic porovnanie
```{r}

# Vytvorenie confusionMatrix matíc pre každý model
glmConfMatrix <- confusionMatrix(as.factor(glmPredictions), testData$warning)
ldaConfMatrix <- confusionMatrix(as.factor(ldaPredictions), testData$warning)
svmConfMatrix <- confusionMatrix(as.factor(svmPredictions), testData$warning)
ldaConfMatrixTweak1 <- confusionMatrix(as.factor(ldaPredictionsTweak1), testData$warning)
svmConfMatrixTweak1 <- confusionMatrix(as.factor(svmPredictionsTweak1), testData$warning)
svmConfMatrixTweak2 <- confusionMatrix(as.factor(svmPredictionsTweak2), testData$warning)


# Vypísanie matíc a súhrnných štatistík
print("GLM Confusion Matrix and Summary:")
print(glmConfMatrix)

print("LDA Confusion Matrix and Summary:")
print(ldaConfMatrix)

print("SVM Confusion Matrix and Summary:")
print(svmConfMatrix)

print("LDA Tweak1 Confusion Matrix and Summary:")
print(ldaConfMatrixTweak1)

print("SVM Tweak1 Confusion Matrix and Summary:")
print(svmConfMatrixTweak1)

print("SVM Tweak2 Confusion Matrix and Summary:")
print(svmConfMatrixTweak2)

```

### Porovnanie ROC kriviek
```{r}

# Výpočet ROC kriviek pre každý model
glm_roc <- roc(response = testData$warning, predictor = as.numeric(glmPredictions))
lda_roc <- roc(response = testData$warning, predictor = as.numeric(ldaPredictions))
svm_roc <- roc(response = testData$warning, predictor = as.numeric(svmPredictions))
lda_rocTweak1 <- roc(response = testData$warning, predictor = as.numeric(ldaPredictionsTweak1))
svm_rocTweak1 <- roc(response = testData$warning, predictor = as.numeric(svmPredictionsTweak1))
svm_rocTweak2 <- roc(response = testData$warning, predictor = as.numeric(svmPredictionsTweak2))


# Vykreslenie ROC kriviek
plot(glm_roc, main="ROC Curves", col="red")
plot(lda_roc, add=TRUE, col="blue")
plot(svm_roc, add=TRUE, col="green")
plot(lda_rocTweak1, add=TRUE, col="black")
plot(svm_rocTweak1, add=TRUE, col="pink")
plot(svm_rocTweak2, add=TRUE, col="orange")
legend("bottomright", legend=c("GLM", "LDA", "SVM", "LDA_TWEAK1", "SVM_TWEAK1", "SVM_TWEAK2"), col=c("red", "blue", "green", "black", "pink", "orange"), lwd=2)

```

### Heatmapy pre Confusion Matrix
```{r}

# Pomocná funkcia na premenu zmätkovej matice na data frame vhodný pre ggplot
conf_matrix_to_df <- function(conf_matrix) {
  df <- as.data.frame(as.table(conf_matrix))
  colnames(df) <- c("Prediction", "Reference", "Frequency")  # Meníme názvy stĺpcov pre zrozumiteľnosť a správne mapovanie
  return(df)
}

# Prevod zmätkových matíc na data frame
glm_df <- conf_matrix_to_df(glmConfMatrix$table)
lda_df <- conf_matrix_to_df(ldaConfMatrix$table)
svm_df <- conf_matrix_to_df(svmConfMatrix$table)
lda_df_Tweak1 <- conf_matrix_to_df(ldaConfMatrixTweak1$table)
svm_df_Tweak1 <- conf_matrix_to_df(svmConfMatrixTweak1$table)
svm_df_Tweak2 <- conf_matrix_to_df(svmConfMatrixTweak2$table)

# Funkcia na vykreslenie heatmapy
plot_conf_matrix <- function(data, title) {
  ggplot(data, aes(x = Prediction, y = Reference, fill = Frequency)) +
          geom_tile(color = "white") +
          scale_fill_gradient(low = "blue", high = "red") +
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
          labs(title = title, x = 'Predicted Class', y = 'Actual Class') +
          geom_text(aes(label = Frequency), vjust = 1.5, color = "white")
}

# Vykreslenie heatmap pre každú zmätkovú maticu
plot_conf_matrix(glm_df, "GLM Confusion Matrix")
plot_conf_matrix(lda_df, "LDA Confusion Matrix")
plot_conf_matrix(svm_df, "SVM Confusion Matrix")
plot_conf_matrix(lda_df_Tweak1, "LDA Tweak1 Confusion Matrix")
plot_conf_matrix(svm_df_Tweak1, "SVM Tweak1 Confusion Matrix")
plot_conf_matrix(svm_df_Tweak2, "SVM Tweak2 Confusion Matrix")

```

### Precision-Recall Curve and AUPRC:
Plocha pod krivkou PR (AUPRC) kvantifikuje celkový výkon klasifikačného modelu.
Vypočítava plochu pod krivkou PR, ktorá predstavuje schopnosť modelu dosiahnuť vysokú presnosť a vysokú odvolávku súčasne pri všetkých možných prahových hodnotách.
vyššia hodnota AUPRC naznačuje lepšiu výkonnosť modelu, pretože znamená väčšiu plochu pod krivkou PR, čo naznačuje, že model môže dosiahnuť vysokú presnosť a vysokú odvolávku pri rôznych prahových hodnotách.
AUPRC je obzvlášť užitočná pri práci s nevyváženými súbormi údajov, kde jedna trieda prevláda oveľa viac ako druhá, pretože sa zameriava na výkonnosť pozitívnej triedy, ktorá môže byť zaujímavejšia.
v súhrne krivka Precision-Recall poskytuje prehľad o kompromise medzi presnosťou a odvolávkou pri rôznych klasifikačných prahoch, zatiaľ čo AUPRC sumarizuje celkovú výkonnosť modelu pri všetkých možných prahoch.
Oba sú cennými nástrojmi na hodnotenie účinnosti klasifikačných modelov, najmä v scenároch, kde je prítomná nerovnováha tried.
```{r}
# Generovanie kriviek PR s parametrom krivky nastaveným na TRUE
# curve parameter musi byt true ak chem plotovat krivku
pr_glm <- pr.curve(scores.class0 = glmPredictions, weights.class0 = testData$warning == 1, curve = TRUE)
pr_lda <- pr.curve(scores.class0 = ldaPredictions, weights.class0 = testData$warning == 1, curve = TRUE)
pr_svm <- pr.curve(scores.class0 = svmPredictions, weights.class0 = testData$warning == 1, curve = TRUE)
pr_lda_Tweak1 <- pr.curve(scores.class0 = ldaPredictionsTweak1, weights.class0 = testData$warning == 1, curve = TRUE)
pr_svm_Tweak1 <- pr.curve(scores.class0 = svmPredictionsTweak1, weights.class0 = testData$warning == 1, curve = TRUE)
pr_svm_Tweak2 <- pr.curve(scores.class0 = svmPredictionsTweak2, weights.class0 = testData$warning == 1, curve = TRUE)


# kontrola štruktúri PR curve objects
str(pr_glm)
str(pr_lda)
str(pr_svm)
str(pr_lda_Tweak1)
str(pr_svm_Tweak1)
str(pr_svm_Tweak2)

plot(pr_glm, col = "red")
lines(pr_lda$recalls, pr_lda$precisions, col = "blue")
lines(pr_svm$recalls, pr_svm$precisions, col = "green")
legend("bottomright", legend = c("GLM", "LDA", "SVM"), col = c("red", "blue", "green"), lty = 1)
```

### F1 Score

#### Precision

meria presnosť pozitívnych predpovedí modelu.
Odpovedá na otázku: "Koľko zo všetkých prípadov, ktoré model predpovedal ako pozitívne, bolo skutočne pozitívnych? Matematicky sa presnosť vypočíta ako:
Vysoká presnosť znamená, že model má tendenciu robiť menej falošne pozitívnych predpovedí.

#### Recall (Sensitivity or True Positive Rate)

meria schopnosť modelu správne identifikovať pozitívne prípady z celkového počtu skutočných pozitívnych prípadov.
Odpovedá na otázku: "Koľko zo všetkých skutočných pozitívnych prípadov model správne predpovedal ako pozitívne?"
Vysoká spätná väzba znamená, že model zachytáva väčšinu skutočných pozitívnych prípadov.

#### F1 Score

je harmonický priemer Precision a Recall, ktorý poskytuje jedinú metriku na vyváženie Precision a Recall.
Je užitočné najmä vtedy, keď potrebujete rovnako zohľadniť falošne pozitívne aj falošne negatívne výsledky.
SkóreF1 dosahuje najlepšiu hodnotu pri 1 (dokonalá presnosť a odvolanie) a najhoršiu pri 0.
```{r}
# extrahujem precision a recall z confusion matrices
precision_glm <- glmConfMatrix$byClass['Pos Pred Value']
recall_glm <- glmConfMatrix$byClass['Sensitivity']
f1_glm <- 2 * (precision_glm * recall_glm) / (precision_glm + recall_glm)

precision_lda <- ldaConfMatrix$byClass['Pos Pred Value']
recall_lda <- ldaConfMatrix$byClass['Sensitivity']
f1_lda <- 2 * (precision_lda * recall_lda) / (precision_lda + recall_lda)

precision_svm <- svmConfMatrix$byClass['Pos Pred Value']
recall_svm <- svmConfMatrix$byClass['Sensitivity']
f1_svm <- 2 * (precision_svm * recall_svm) / (precision_svm + recall_svm)

precision_lda_Tweak1 <- ldaConfMatrixTweak1$byClass['Pos Pred Value']
recall_lda_Tweak1<- ldaConfMatrixTweak1$byClass['Sensitivity']
f1_lda_Tweak1 <- 2 * (precision_lda_Tweak1 * recall_lda_Tweak1) / (precision_lda_Tweak1 + recall_lda_Tweak1)

precision_svm_Tweak1 <- svmConfMatrixTweak1$byClass['Pos Pred Value']
recall_svm_Tweak1 <- svmConfMatrixTweak1$byClass['Sensitivity']
f1_svm_Tweak1 <- 2 * (precision_svm_Tweak1 * recall_svm_Tweak1) / (precision_svm_Tweak1 + recall_svm_Tweak1)

precision_svm_Tweak2 <- svmConfMatrixTweak2$byClass['Pos Pred Value']
recall_svm_Tweak2 <- svmConfMatrixTweak2$byClass['Sensitivity']
f1_svm_Tweak2 <- 2 * (precision_svm_Tweak2 * recall_svm_Tweak2) / (precision_svm_Tweak2 + recall_svm_Tweak2)


print(paste("GLM F1 Score:", f1_glm))
print(paste("LDA F1 Score:", f1_lda))
print(paste("SVM F1 Score:", f1_svm))
print(paste("LDA Tweak1 F1 Score:", f1_lda_Tweak1))
print(paste("SVM Tweak1 F1 Score:", f1_svm_Tweak1))
print(paste("SVM Tweak2 F1 Score:", f1_svm_Tweak2))

```
